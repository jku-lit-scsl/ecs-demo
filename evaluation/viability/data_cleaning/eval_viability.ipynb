{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Helper Functions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a2e55ad90a37334f"
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9ec23465437583b8",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-12T21:13:09.314636600Z",
     "start_time": "2024-02-12T21:13:09.285274400Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "ip_pattern = r'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}'"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get only defcon changes"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1ad7239458f7a63f"
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "\n",
    "# Function to parse the log file and extract only WARNING log entries\n",
    "def extract_warning_logs(input_path, output_path):\n",
    "    with open(input_path, 'r') as input_file, open(output_path, 'w') as output_file:\n",
    "        for line in input_file:\n",
    "            if \"WARNING\" in line:\n",
    "                output_file.write(line)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T21:13:09.327634200Z",
     "start_time": "2024-02-12T21:13:09.289814200Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Concat timestamps of log files"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2720c7ba1ca94156"
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "def get_log_files(directory):\n",
    "    \"\"\"\n",
    "    Retrieves all log files in the specified directory.\n",
    "\n",
    "    :param directory: Path to the directory to search for log files.\n",
    "    :return: List of paths to log files found in the directory.\n",
    "    \"\"\"\n",
    "    log_files = [os.path.join(directory, file) for file in os.listdir(directory) if file.endswith('.log')]\n",
    "    return log_files\n",
    "\n",
    "\n",
    "def concat_timestamps_for_dir(directory_path):\n",
    "    for log_file in get_log_files(directory_path):\n",
    "        extract_warning_logs(log_file, log_file.replace('_eval.log', '_defcon_warn.log'))\n",
    "        if 'trigger' in log_file:\n",
    "            extract_warning_logs(log_file, log_file.replace('_eval_trigger.log', '_trigger_defcon_warn.log'))\n",
    "\n",
    "    # Updated Regex to match log entries and extract timestamp including milliseconds\n",
    "    log_entry_pattern = r'(\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}\\.\\d{3}).*Increased defcon mode to: defcon_4_monitoring'\n",
    "\n",
    "    # Function to read the triggerdefcon file and extract relevant log entries\n",
    "    def extract_defcon_entries(file_path, pattern):\n",
    "        defcon_entries = []\n",
    "        with open(file_path, 'r') as file:\n",
    "            for line in file:\n",
    "                match = re.search(pattern, line)\n",
    "                if match:\n",
    "                    defcon_entries.append(match.group(1))\n",
    "        return pd.DataFrame(defcon_entries, columns=['Timestamp'])\n",
    "\n",
    "    # Function to append timestamps from other log files within the same minute\n",
    "    def append_timestamps_from_files(df, log_file_paths, pattern):\n",
    "        for file_path in log_file_paths:\n",
    "            if 'trigger_defcon' in file_path or not '_warn' in file_path:\n",
    "                continue\n",
    "\n",
    "            file_timestamps = []\n",
    "            with open(file_path, 'r') as file:\n",
    "                for line in file:\n",
    "                    match = re.search(pattern, line)\n",
    "                    if match:\n",
    "                        # Now including milliseconds in the parsing format\n",
    "                        file_timestamps.append(datetime.strptime(match.group(1), '%Y-%m-%d %H:%M:%S.%f'))\n",
    "\n",
    "            # For each timestamp in the trigger file, search for entries within the same minute in this file\n",
    "            search_results = []\n",
    "            for trigger_timestamp in df['Timestamp']:\n",
    "                start_window = trigger_timestamp\n",
    "                end_window = trigger_timestamp + timedelta(minutes=1)\n",
    "                matching_timestamp = next((ts for ts in file_timestamps if start_window <= ts < end_window), None)\n",
    "                search_results.append(matching_timestamp)\n",
    "            \n",
    "            match = re.search(ip_pattern, file_path)\n",
    "            # Extract the IP address if a match is found\n",
    "            ip_address = match.group(0)\n",
    "            df[ip_address] = search_results\n",
    "\n",
    "        return df\n",
    "\n",
    "    # Assuming directory_path is set correctly\n",
    "    log_file_paths = get_log_files(directory_path)\n",
    "    trigger_file = next((f for f in log_file_paths if 'trigger_defcon_warn' in f), None)\n",
    "\n",
    "    if trigger_file:\n",
    "        # Create the initial DataFrame from the triggerdefcon file\n",
    "        df_defcon = extract_defcon_entries(trigger_file, log_entry_pattern)\n",
    "        df_defcon['Timestamp'] = pd.to_datetime(df_defcon['Timestamp'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "\n",
    "        # Append timestamps from other log files within the same minute\n",
    "        # df_defcon_complete = pd.DataFrame()\n",
    "        df_defcon_complete = append_timestamps_from_files(df_defcon, log_file_paths, log_entry_pattern)\n",
    "\n",
    "        # Display the head of the complete DataFrame\n",
    "        return df_defcon_complete\n",
    "    else:\n",
    "        print('Trigger file not found')\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T21:13:09.342633900Z",
     "start_time": "2024-02-12T21:13:09.298804200Z"
    }
   },
   "id": "de03d867ae699d75"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Calculate delays"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "53aa8242886b0100"
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "def calculate_longest_delay(df):\n",
    "    # Initialize a list to store the longest delay for each row\n",
    "    longest_delays = []\n",
    "\n",
    "    # Iterate over DataFrame rows\n",
    "    for index, row in df.iterrows():\n",
    "        # Extract the first timestamp from the trigger file\n",
    "        trigger_timestamp = row['Timestamp']\n",
    "\n",
    "        # Initialize a variable to keep track of the longest delay for the current row\n",
    "        max_delay = pd.Timedelta(0)\n",
    "\n",
    "        # Iterate over all other columns to calculate delays\n",
    "        for col in df.columns[1:]:  # Skipping the first column as it's the trigger timestamp\n",
    "            if pd.isnull(row[col]):\n",
    "                continue  # Skip if the timestamp is NaN\n",
    "            # Calculate the time difference\n",
    "            current_delay = row[col] - trigger_timestamp\n",
    "            # Update max_delay if the current delay is longer\n",
    "            if current_delay > max_delay:\n",
    "                max_delay = current_delay\n",
    "\n",
    "        # Append the longest delay for the current row to the list\n",
    "        longest_delays.append(max_delay)\n",
    "\n",
    "    # Add the list as a new column to the DataFrame\n",
    "    df['LongestDelay'] = longest_delays\n",
    "    return df\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T21:13:09.342633900Z",
     "start_time": "2024-02-12T21:13:09.304156400Z"
    }
   },
   "id": "c79f99df24d2baca"
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Assuming df_defcon_complete_with_delays is your DataFrame containing the 'LongestDelay' column\n",
    "# # First, convert the 'LongestDelay' column to total seconds for plotting\n",
    "# df_defcon_complete_with_delays['LongestDelaySeconds'] = df_defcon_complete_with_delays[\n",
    "#     'LongestDelay'].dt.total_seconds()\n",
    "# \n",
    "# # Now, create a boxplot for the 'LongestDelaySeconds' column\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.boxplot(df_defcon_complete_with_delays['LongestDelaySeconds'].dropna(), vert=False)\n",
    "# plt.title('Boxplot of Longest Delays')\n",
    "# plt.xlabel('Seconds')\n",
    "# plt.ylabel('Longest Delay')\n",
    "# plt.grid(True)\n",
    "# \n",
    "# # Show the plot\n",
    "# plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T21:13:09.342633900Z",
     "start_time": "2024-02-12T21:13:09.309637400Z"
    }
   },
   "id": "f6532f52ab30e756"
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[89], line 30\u001B[0m\n\u001B[0;32m     27\u001B[0m df_r2 \u001B[38;5;241m=\u001B[39m concat_timestamps_for_dir(directory_path_r2)\n\u001B[0;32m     28\u001B[0m df_r3 \u001B[38;5;241m=\u001B[39m concat_timestamps_for_dir(directory_path_r3)\n\u001B[1;32m---> 30\u001B[0m df_r1_short \u001B[38;5;241m=\u001B[39m \u001B[43mget_exactly_tewnty_rows\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf_r1\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     31\u001B[0m df_r2_short \u001B[38;5;241m=\u001B[39m get_exactly_tewnty_rows(df_r2)\n\u001B[0;32m     32\u001B[0m df_r3_short \u001B[38;5;241m=\u001B[39m get_exactly_tewnty_rows(df_r3)\n",
      "Cell \u001B[1;32mIn[89], line 4\u001B[0m, in \u001B[0;36mget_exactly_tewnty_rows\u001B[1;34m(df)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_exactly_tewnty_rows\u001B[39m(df):\n\u001B[0;32m      2\u001B[0m     \u001B[38;5;66;03m# Assuming df is your DataFrame\u001B[39;00m\n\u001B[0;32m      3\u001B[0m     \u001B[38;5;66;03m# Check if the last row has any NA values\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miloc\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39misna()\u001B[38;5;241m.\u001B[39many():\n\u001B[0;32m      5\u001B[0m         \u001B[38;5;66;03m# Drop the last row if it has any NA values\u001B[39;00m\n\u001B[0;32m      6\u001B[0m         df \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39miloc[:\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;66;03m# Ensure the DataFrame has at least 20 rows\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexing.py:1153\u001B[0m, in \u001B[0;36m_LocationIndexer.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   1150\u001B[0m axis \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maxis \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m   1152\u001B[0m maybe_callable \u001B[38;5;241m=\u001B[39m com\u001B[38;5;241m.\u001B[39mapply_if_callable(key, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj)\n\u001B[1;32m-> 1153\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_getitem_axis\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmaybe_callable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexing.py:1714\u001B[0m, in \u001B[0;36m_iLocIndexer._getitem_axis\u001B[1;34m(self, key, axis)\u001B[0m\n\u001B[0;32m   1711\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot index by location index with a non-integer key\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1713\u001B[0m \u001B[38;5;66;03m# validate the location\u001B[39;00m\n\u001B[1;32m-> 1714\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_integer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1716\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39m_ixs(key, axis\u001B[38;5;241m=\u001B[39maxis)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexing.py:1647\u001B[0m, in \u001B[0;36m_iLocIndexer._validate_integer\u001B[1;34m(self, key, axis)\u001B[0m\n\u001B[0;32m   1645\u001B[0m len_axis \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39m_get_axis(axis))\n\u001B[0;32m   1646\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m key \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m len_axis \u001B[38;5;129;01mor\u001B[39;00m key \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m-\u001B[39mlen_axis:\n\u001B[1;32m-> 1647\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mIndexError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msingle positional indexer is out-of-bounds\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mIndexError\u001B[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "def get_exactly_tewnty_rows(df):\n",
    "    # Assuming df is your DataFrame\n",
    "    # Check if the last row has any NA values\n",
    "    if df.iloc[-1].isna().any():\n",
    "        # Drop the last row if it has any NA values\n",
    "        df = df.iloc[:-1]\n",
    "\n",
    "    # Ensure the DataFrame has at least 20 rows\n",
    "    if len(df) > 20:\n",
    "        # Keep only the last 20 rows\n",
    "        df = df.tail(20)\n",
    "    else:\n",
    "        print('Error: df has less than 20 rows...')\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Assume directory_path is correctly defined as needed\n",
    "node_names = ['ed_02', 'fog_01']\n",
    "\n",
    "for node_name in node_names:\n",
    "    directory_path_r1 = os.path.join(node_name, 'r1')\n",
    "    directory_path_r2 = os.path.join(node_name, 'r2')\n",
    "    directory_path_r3 = os.path.join(node_name, 'r3')\n",
    "\n",
    "    df_r1 = concat_timestamps_for_dir(directory_path_r1)\n",
    "    df_r2 = concat_timestamps_for_dir(directory_path_r2)\n",
    "    df_r3 = concat_timestamps_for_dir(directory_path_r3)\n",
    "\n",
    "    df_r1_short = get_exactly_tewnty_rows(df_r1)\n",
    "    df_r2_short = get_exactly_tewnty_rows(df_r2)\n",
    "    df_r3_short = get_exactly_tewnty_rows(df_r3)\n",
    "\n",
    "    df_concat = pd.concat([df_r1_short, df_r2_short, df_r3_short], ignore_index=True)\n",
    "    \n",
    "    df_concat_delay = calculate_longest_delay(df_concat)\n",
    "    break\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T21:13:09.403240900Z",
     "start_time": "2024-02-12T21:13:09.316638Z"
    }
   },
   "id": "b2b9b580efb42930"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T21:13:09.409239400Z",
     "start_time": "2024-02-12T21:13:09.406241700Z"
    }
   },
   "id": "72f6c2843f632bfe"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
